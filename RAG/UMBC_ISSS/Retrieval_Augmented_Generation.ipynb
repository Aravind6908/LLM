{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNeGhetYrO7j"
   },
   "source": [
    "### ***RAG Model***<br>\n",
    "This notebook implements the RAG system using GPT-3.5 for query answering over UMBC ISSS Data.<br>\n",
    "***Key Components:***\n",
    "* ***Embeddings:***<br>\n",
    "<tb>Generated using the sentence-transformers/all-mpnet-base-v2 model.<br>\n",
    "* ***Hybrid Retrieval:***<br>\n",
    "FAISS for dense retrieval and BM25 for sparse keyword-based retrieval.<br>\n",
    "Hybrid retrieval combines FAISS and BM25 for accuracy.<br>\n",
    "* ***Generation:***<br>\n",
    "GPT-3.5 processes top-ranked context to generate detailed and accurate responses.<br>\n",
    "* ***Evaluation:***<br>\n",
    "Tested on 20 FAQs with metrics like Cosine Similarity and BERTScore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVa347ImCJYL"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0Szt6PKm47Ic",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "91137cb7-9094-4247-d9d0-b3cffc58c387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.54.4\n",
      "    Uninstalling openai-1.54.4:\n",
      "      Successfully uninstalled openai-1.54.4\n",
      "Successfully installed openai-0.28.0\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting rank-bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank-bm25, faiss-cpu\n",
      "Successfully installed faiss-cpu-1.9.0.post1 rank-bm25-0.2.2\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.46.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28\n",
    "!pip install faiss-cpu rank-bm25 sentence-transformers\n",
    "!pip install  bert-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrFbYPuPj3Pb"
   },
   "source": [
    "## **Data Loading from Github**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Nw0rc4fxihPV",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ce0d13c1-3238-4028-ac05-0ac4c9fcf6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/About_OISS.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Admitted_Student_Events_and_Orientation.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Admitted_Student_Events_and_Orientation.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Applying_to_UMBC.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Applying_to_UMBC.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/CPT.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/CPT.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/CPT.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/CPT.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/CPT.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Career_Center.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Change_of_Education_or_Degree_Level.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Change_of_Education_or_Degree_Level.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Contact_Us.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Contact_Us.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Economic_Hardship_Work_Authorization.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Economic_Hardship_Work_Authorization.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Economic_Hardship_Work_Authorization.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Economic_Hardship_Work_Authorization.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Education_Abroad_for_International_Students.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Education_Abroad_for_International_Students.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Entering_the_USA.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Entering_the_USA.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Entering_the_USA.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Entering_the_USA.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Entering_the_USA.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Entering_the_USA.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk6.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk7.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Enrollements_and_Requirements.docx_chunk8.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk6.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk7.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk8.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/F1_Visa_Process.docx_chunk9.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Financing_Your_Studies.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Financing_Your_Studies.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Financing_Your_Studies.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Graduate_Assistantships.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Graduate_Assistantships.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Graduate_Assistantships.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Graduate_Assistantships.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/H1-B_Overview.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/H1-B_Overview.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/H1-B_Overview.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/H1-B_Overview.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/H1-B_Overview.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/H1-B_Overview.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/H1-B_Overview.docx_chunk6.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Health_Insurance_and_Immunization_Requirements.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Health_Insurance_and_Immunization_Requirements.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/I-20_Program_Extension.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/I-20_Program_Extension.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Immigration_Options_after_Graduation.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/In_State_Tuition_Fees.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/International_Student_Orientation.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Loss_and_Reinstatement_of_F1.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Loss_and_Reinstatement_of_F1.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Loss_and_Reinstatement_of_F1.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Meet_the_Staff.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Meet_the_Staff.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OISS_Staff.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT_and_STEM_OPT_Best_Practices%20_for_H1B.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT_and_STEM_OPT_Best_Practices%20_for_H1B.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT_and_STEM_OPT_Best_Practices%20_for_H1B.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT_and_STEM_OPT_Best_Practices%20_for_H1B.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/OPT_and_STEM_OPT_Best_Practices%20_for_H1B.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/On_Campus_work.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/On_Campus_work.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Packing_Tips.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Packing_Tips.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Packing_Tips.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Passport.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/PhD_Student_OPT_Planning.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/PhD_Student_OPT_Planning.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/SEVP_Portal_Help.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/SEVP_Portal_Help.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/SEVP_Portal_Help.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/SEVP_Portal_Help.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/SEVP_Portal_Help.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/SEVP_Portal_Help.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/SEVP_Portal_Help.docx_chunk6.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk6.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/STEM_OPT_Extension.docx_chunk7.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Start_Planning_to_Arrive_at_UMBC.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Start_Planning_to_Arrive_at_UMBC.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Studying_in_the_USA.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Taxes_for_students_on_OPT.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Taxes_for_students_on_OPT.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Transfer_i20.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Transfer_i20.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Transfer_i20.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Transfer_i20.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Transfer_out_during_OPT.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal.docx_chunk5.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal_During_OPT.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal_During_OPT.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Travel_Abroad_and_Visa_Renewal_During_OPT.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Tuition_fees.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Tuition_fees.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Tuition_fees.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Visiting_the_USA_on_B-2_Visitor_Visa.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Welcome_to_CGE.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Welcome_to_CGE.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Welcome_to_CGE.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Welcome_to_ISSS.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/Welcome_to_ISSS.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/i20.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/i20.docx_chunk1.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/i20.docx_chunk2.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/i20.docx_chunk3.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/i20.docx_chunk4.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/i20_Access.docx_chunk0.json\n",
      "Loaded URL: https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/processed_documents/i20_Access.docx_chunk1.json\n",
      "Loaded 493 documents.\n",
      "Loaded 20 FAQs.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# GitHub repository details\n",
    "repo_owner = \"Aravind6908\"\n",
    "repo_name = \"datahub\"\n",
    "folder_path = \"LLM/processed_documents\"\n",
    "\n",
    "# Function to fetch JSON files from GitHub API\n",
    "def fetch_files_from_github_folder(owner, repo, folder):\n",
    "    base_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{folder}\"\n",
    "    try:\n",
    "        response = requests.get(base_url)\n",
    "        response.raise_for_status()\n",
    "        file_urls = []\n",
    "        for item in response.json():\n",
    "            if item['type'] == 'file' and item['name'].endswith('.json'):\n",
    "                file_urls.append(item['download_url'])\n",
    "        return file_urls\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching folder contents from GitHub: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Fetch list of JSON files in the folder\n",
    "document_files = fetch_files_from_github_folder(\"Aravind6908\", \"datahub\", \"LLM/processed_documents\")\n",
    "\n",
    "# Initialize a list to store all text chunks\n",
    "documents = []\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    processed_text = []\n",
    "    for key, value in chunk.items():\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    section_info = \"; \".join(f\"{k}: {v}\" for k, v in item.items())\n",
    "                    processed_text.append(f\"{key} - {section_info}\")\n",
    "        elif isinstance(value, dict):\n",
    "            nested_info = \"; \".join(f\"{k}: {v}\" for k, v in value.items())\n",
    "            processed_text.append(f\"{key} - {nested_info}\")\n",
    "        else:\n",
    "            processed_text.append(f\"{key}: {value}\")\n",
    "\n",
    "    return \" | \".join(processed_text)\n",
    "\n",
    "\n",
    "# FAQ URL\n",
    "faq_url = \"https://raw.githubusercontent.com/Aravind6908/datahub/main/LLM/FAQ.json\"\n",
    "\n",
    "# fetch and parse JSON from raw GitHub URLs\n",
    "def fetch_json_from_github(raw_url):\n",
    "    try:\n",
    "        response = requests.get(raw_url)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        return response.json()  # Parse JSON content\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching file from GitHub: {raw_url}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON from file: {raw_url}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# Fetch and process each document file\n",
    "for file_url in document_files:\n",
    "    data = fetch_json_from_github(file_url)\n",
    "    if data:\n",
    "        chunk_text = data.get('ChunkText')\n",
    "        if isinstance(chunk_text, dict):\n",
    "            documents.append(process_chunk(chunk_text))\n",
    "        elif isinstance(chunk_text, str):\n",
    "            documents.append(chunk_text)\n",
    "        else:\n",
    "            print(f\"Loaded URL: {file_url}\")\n",
    "\n",
    "# Check the number of documents loaded\n",
    "print(f\"Loaded {len(documents)} documents.\")\n",
    "\n",
    "# Load preprocessed FAQs\n",
    "faqs = fetch_json_from_github(faq_url)\n",
    "if faqs:\n",
    "    print(f\"Loaded {len(faqs)} FAQs.\")\n",
    "else:\n",
    "    print(\"Failed to load FAQs.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "MoHeFvoEin5q",
    "outputId": "dbe8923c-0aa1-4eb7-cde3-73eb5f1608e7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'about oiss umbc office of international students and scholars the office of international students and scholars oiss is dedicated to supporting umbcs international student and scholar community. the office offers a variety of programming and services to assist students and scholars in pursuit of their academic, personal, and professional goals.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K71oMLx3z9zT"
   },
   "source": [
    "\n",
    "## **Embeddings:**\n",
    "Generated using the sentence-transformers/all-mpnet-base-v2 model.\n",
    "\n",
    "## **Improving Retrieval with FAISS**\n",
    "1. Hybrid Retrieval (Sparse + Dense):\n",
    "Combine FAISS with traditional search like BM25. Sparse retrieval methods, like BM25, provide better keyword matching, while FAISS provides context. You can then score documents from both and use a reranker to get optimal results.\n",
    "al performance by expanding the coverage of relevant content.\n",
    "4. Re-Ranking:\n",
    "Re-rank the top-k documents returned by FAISS using a fine-tuned BERT model to make sure the most relevant document appears first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877,
     "referenced_widgets": [
      "d52e79fd61494fae9acc36a5e3daa754",
      "b4a814cd80ff432f9dd20e94d260350c",
      "48aa44efaf634a998ed6c505436bce05",
      "0546b6161d884b25bb20ccbd914d9232",
      "2f22c390a3ec4d94b8fbfd9f4a594963",
      "1e66ba50751b43fe8e0ef6ed5b2e66cb",
      "e1b41e15f4b541f99afabba85db3de68",
      "16b6cf87a7f3454b8987163613c519f5",
      "a98ef559c52843689aa1dbeb6fab2cc1",
      "067f3cb6a2c14c1c935800e02a8332f9",
      "30082e90ef1b4c0baa3b57e73b44492d",
      "c07179460ba44cc4a3e35c8125c9b5a2",
      "d0c3e16dfeb24f22a5199a24ec06fbf9",
      "81c9071969a544cfaf0852aa09e24bb7",
      "7233d748e0854cd186e96fba82109685",
      "02516e9d116a457589c02ffebed41d59",
      "704e91cecff94a88b7165b6107674fe4",
      "fd50b8527e2b46f19e0e88246d770d50",
      "e98c5cd4fffb48ce9ffa09578022e72a",
      "5112844b87c24213a6a1ce8b628ccf93",
      "ac0f621bb7ea4779a54be4ebe512640e",
      "0076c445e9444963ba1d2f481f03e90f",
      "9e63ee6dff924407b0fbd606133fb1fa",
      "2f74decfd7304f83b91a380682dc11e6",
      "9cb1b84bfa574e6783f3c2496cbd9506",
      "8a7bcb0166b945d093373938c608ac2e",
      "e00dccef7b54424f966ca3f07aea4167",
      "46051513a01045889a128c1ba68c0a2d",
      "e92e1aeccf94418ba2247659d53e2956",
      "6376125aeab94d59a8c011eb4b27beba",
      "023bb17fc7a64d748fb38b2a0b3ad484",
      "3dbe021d9d0045dbbbe51fe4b7ac2a14",
      "cbbcf0f90fc349c9985cef90c851c0b8",
      "2b8f22e4d9ef4806aaa84f00ab027826",
      "328fe1c008524483b063ad8b7fb89760",
      "5f82fdc19cb94383aa319ae62333ea9f",
      "12db2a5047a747abb19a34325e919295",
      "074febd8a2e24887a61e0321d4352cdf",
      "4d391fcc1e8547b4b8c69f184be80df9",
      "93172d875bd643539e5c1b8549acffb7",
      "ae866dac85dc4c0a98a8f3c6bd3399d0",
      "de20ac0440d24330ad61b3c5c7d96596",
      "d8c085d62dd745d68865e450215157d1",
      "756f22dd1f9243ba8068f8765096449e",
      "8829f4b41d6f4608b80f4faebb7cf119",
      "71bfe6a094f846c3a0773f58151ca8fe",
      "24474b976c0c485286f8098276f46dc2",
      "f2b4f914a1984eec8b75b8d704ea0f5d",
      "ed06e12f2373412eb4b4ab5cb4faa08b",
      "15f97f6c0d744d878b0100b14d85b5b5",
      "8f6c92c0d2d74f4c8c08eecaad16bf3c",
      "a5d56ca52404450092a4509f713406ea",
      "88ed3cac2f5d46839bf51f4727e7757c",
      "57281afbdf8643eeba04f213c38a9414",
      "0cfcdf2016934b84b4f13a683aa8d9fc",
      "a9985c201b0c4acb998a0f833850c549",
      "9fc72d97ecbd41a0895ded2197e43827",
      "8c7660047bc54e759be3648f9e25e87c",
      "cdbba4c6c55a428a8db41f68af8e2f5c",
      "994fc85de94248b59ddf51eb92fb3e50",
      "50e1cebd53f54578b7c3515220bf550f",
      "e4e9a683a44a45b7a3d6cc92749c4c87",
      "85e9511f294f4949b7ba811428d10dcb",
      "197a37da54824637baa3ce96dad01123",
      "6a9fc9a36ff242759c5d6bb039a5c896",
      "c4bdd8b91d5a4bcfac21d5908a90f720",
      "c5e65416cd7d4641937235563b0b7ae1",
      "9598f37a0719436888f1425ab6e2d3d1",
      "925f80e91e42404facd00267752aab3d",
      "a0077f16252b4095b730d9997e43d67c",
      "6641d59a117d4975832a7df4887230cd",
      "51f83b1981274ac29ea3cec362888bfb",
      "31470422d7a8445c9edd045d9cf257fb",
      "1a31d6caf84a4dc4a2e0e076e2005ef3",
      "b3b443f04c8e48d6bbeac772fee505d3",
      "796d9bd20ca340d7af3aa2b85195da39",
      "6b92ea3d645040a6941661c115dc965b",
      "d0a8e5ada9b5487eb398a781623e5a0b",
      "9c1c409789224bcc848f6a4f566363aa",
      "6f292d629faa453f85c5e5749d6dfc8c",
      "06f68906ad5b4ec2a04fc550e0f42734",
      "d54db5a8165f4d948c350e0106ad8ccf",
      "08941730a4064e8584dd55a6ee116ace",
      "0c9f598a614d4df5bca07df5a1c166a9",
      "30216a9486a94ec2b05e576c71aa447a",
      "916b2f5ed6d441e892eedceea489cacb",
      "a4b429d457534bf6a2a637152b41ea6d",
      "7e28ddaa21354c28b1c26e7c00067394",
      "7c80469592134bdf9db0a1ec9232e577",
      "df89ba7b45b2436dbf590e20a6e52870",
      "3b0f72f6f23a42108c99c3043e535e1a",
      "0e7c9716d810411aaa61ff2fd9aaa07d",
      "cfbf34138de94ad7aa5aa1708a7ac9f2",
      "c439f297b1f5440da1fc8a6a34d846d8",
      "f78100652da44cbf9736332dcf4aa8d5",
      "3bd8fea0b61142e8985fed562d8cfa20",
      "85599ac17e5446799d69022f80515a75",
      "0ea595b995a249539b5e9e3cc08a77b8",
      "044339e5ee3f45f290cea6c8b043da27",
      "e0a2cc30a2c447159ba027a0bdbdc050",
      "3ec1d56e99474cb5aa53d13a76860208",
      "5e04de9e418845568e3ab3ea069b1e76",
      "0dfef75f3f6e4bc0b0180be61f523367",
      "cf464bf0bc09408abcd6427adfb2bcc5",
      "f56e2bfcb1dc4b15b2e202b2dd4dd6b3",
      "abb910b144ce4f24b8354056dacb9ee1",
      "7091a63a19bc49b79a4c70c9f169ab28",
      "0f991633c8754f3880b115e7ca2b2bb2",
      "1364173c8905494ebf90856100790047",
      "f55ff1ffd7b449b8b236cca13a82727d",
      "347ceb56cecd4bf4bd4064819490a10a",
      "4a1cefaa5deb42b9af0edbbe7c46421b",
      "27c7b14575f7478db2329d5944888950",
      "55b62c9cf716469f94f918218aa0df8d",
      "fa6afed2b598473f9fb676fcdeb60b95",
      "16d42babb94748bbbb6855519318fb53",
      "e7edd5c2281340c3833c2edccd0d11d0",
      "028334fc4ac04afba1143e3d5bd7d6e1",
      "f76660cc49e3499f8ff450f58f37bd74",
      "17280ef130d045e89a2edfb547fbdb97",
      "ff9351e146a44923b1f9a484ee3764e8",
      "eb3437fed2924645ae48d3795ca57fc9",
      "57ec2871a5324367aa2e1b07611d309b",
      "848643c4b1574666b14d8c9fbeffb832",
      "91278e915470459bb50fcb7717fff5bb",
      "df27dc64980e40c2b6be3ff89f8c03a4",
      "b265b2431cdf46ac8468e7b8d30435dc",
      "d039a98a4dd94117bc054b8f3eb626ab",
      "53e311e8a4a141db8b94f96ccebc4918",
      "ab8600eac5d94e66b8b6aed84c8b469e",
      "a7779e28f84146ed826caa6584d6d9ba",
      "aa217fbf4171449caab2ba98e047343d",
      "0a96c21f35514fe2a1ecc47e8c51c8fc",
      "47145f6cbe8344e3aec9899602954e3a",
      "cf0b81990b884ecd8bf215b1473e301c",
      "dcb17d671b4a460f8d9af534e5ee2c9a",
      "0b65a451770b471398727264a1a5f963",
      "4be21392784e44168efeeab10564a168",
      "e17148f205214765b1437143501d6f50",
      "54e2a79dcbbf4c1da1783c1c13f999df",
      "b0c1c6d633854a6ea12916d1bb957109",
      "84ee65a13ad44cc88b6ef82d972e3f47",
      "33cbe3e18b634fd79e55b59c96f162d7",
      "44cdf1f3bbf24d349d28fcbb9c89e29e",
      "832b01b18cd54b6f8b563c24655ba2b4",
      "790483ccbc684cdca25e4cda0bcf5f7a",
      "707951198f02489aae9416483a178193",
      "865e11f3d8a941b6ae2598c9e3f581c9",
      "0a326f1225b54c7083bbb6d975c3457d",
      "d27603bbe6994f35b1c4744e2ed9b180",
      "e7be75b3c2454b29960b63d367079b83",
      "ef2d97f844a54f66a694a40ab5937654",
      "f321dee34fc1428db9009409baf860d0",
      "8df7dc755fea4ba1ac5e8d7fd0700861",
      "bdd171e7af8b476298b823f7082c86c3",
      "940ae1119ffb465086165017fa687cee",
      "d455515a585f41f793a5de22be543e80",
      "7875781e98bb49beba757690b7e878f6",
      "6ab0288db1e34dcea3f08fe4b2499a5a",
      "fa1885f35fa24746951d5caef77e7f0b",
      "f82b7db4213542d5bff93f782bb5693c",
      "626e7d471080469dbbc12e363a7f4a1b",
      "dec15735cccf42a5a2ac5746df9c2e9e",
      "f49a460bb128429784a07dbf18c713c6",
      "1cc1b306f5314765ba9e22e01109f31e",
      "350ef14468b84cf2a560a767e657aaf8",
      "272869e49035498bb36b4a01b099968e",
      "732dd08a911e4b2dbf9d9c6b1489a303",
      "347191f616574a499f5e33f6389a7979",
      "6ad10c169ac2448bb0afcb93cd86c2e6",
      "24c1d59472e441bc8eade4d797f43678",
      "53fa0ce20eb2492e9ea856dd17ffb384",
      "e3da2c9ea37e4eae9b11af75b32589bf",
      "9a4805ac2fb64dedadb40d44167a27fe",
      "f864f4b9b7334cad9e034d7787c3606b",
      "a8d8f60edac248af9ab6ef389ce94d68",
      "6cdb8810e3b34b8d863cfbbbe764600c",
      "66305e4e7f1b42589073f48a5f4aa1a9",
      "ad98692820a84767bf5edd6a3f239aa3",
      "db359c5b17574848b42080e3d80ad5ba",
      "bbc9eabfff0f4c1993d37b4c00ed45ba",
      "bb38e54d4eac43668a783f2a1db1f16a",
      "57ec16c2eb6b4de2bf2a9add858326bb",
      "079855cb87764f6e821e0dc70fff61b9",
      "ecb01b16179d4657a61b5e236678de73",
      "dcb4b09677654f63a1bade756a5c8883",
      "7babb437965748e88f952aa5f23b40bd",
      "f3ac0c57f42546c88bdf2959afa05374",
      "465ace55844a4e67bb698c25b16bafa5",
      "709db7e8d77d42bbbb9bc6b97632d134",
      "960be09367c643c9a9c0ea5fa96a1b0b",
      "305b85288c784118857a8fb1a003077e",
      "fcbe5e176f2d4a13a76bfeaf8f1d46b6",
      "14655f56c4be4cc1a5f650266755ea2b",
      "9fc9de54e474470cb1dd52840a2a392c",
      "17b47befffb54bb9b8b369263bbaf044",
      "9806adbd099043da93a8b00baf28c2ab",
      "b480c9cac59a4323bd8ce65608d2edc2",
      "7e057c936e034c649fe93028f33d0b80",
      "7a9b64d459dc4e26a6515af880653246",
      "5a8a9eb19bd54a7ea9fe03de549ade39",
      "dba53a84e2c5482689eafae3919e5eda",
      "c4ac984ef5d546ea8c66317619b7106d",
      "4393a9afacd6459a963e7a4cdb86040f",
      "45163991a0614df4854ff9b4b6be1df0",
      "345e53dfcafb48e5823d8d65ed8b1631",
      "08ca19394e854fefa474c5067a4e3078",
      "3ba61dcae23944d7965b2dd84cde344a",
      "8ae334dd0ec44f20923a439af17f5d23",
      "2132fe162a9d4b46b186539576e286c3",
      "0d42729b6f224cdbacd14cd06c70bf44",
      "f57e4fe46ad7468e997c8f5285bb07a5",
      "4e3750f97f434aaeb1dbd9a331746523",
      "d23b8caab35f4c8fb533b14682714014",
      "8711c11f1c904b7ba55a5f14f23de3a9",
      "3ff48dfebb16417fb4af55d6cececb15",
      "cf8ff80d88e347af9ea0f2ff572eec9e",
      "51bc3ac233c849c1babe7c992d2aeb70",
      "16d3b979412641a7bfc833bcd2ef0f2d",
      "859c187f88664b95ac173a39e8182353",
      "4340e555dd674e1dbab9ea43929ba5b3",
      "0d048eb963ef466cbab0bcb9694c862d",
      "8a0314bd87cd46b28b37a810061e44ec",
      "b18459e3dda84072a65a34f5fb024bc4",
      "bce25f40e3064178ad02a06c0ef88c96",
      "1067aed742fd4a60b741af28cbe9b012",
      "a8f4d0d6583d4d369c0150f330cf589f",
      "d4b521ad4f994c00ad0016c289ba78f1",
      "92abb1d1e76b4cc3895cd293c04a6462",
      "9c09fa9a75fb48a28e955782c6b07836",
      "090e8d66857c4c7186c403ce4a59c583"
     ]
    },
    "id": "ZEAHbzz-rAOc",
    "outputId": "5f17cf36-21a3-4b25-a004-0fd81f94f7f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e79fd61494fae9acc36a5e3daa754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07179460ba44cc4a3e35c8125c9b5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e63ee6dff924407b0fbd606133fb1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f22e4d9ef4806aaa84f00ab027826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8829f4b41d6f4608b80f4faebb7cf119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9985c201b0c4acb998a0f833850c549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e65416cd7d4641937235563b0b7ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a8e5ada9b5487eb398a781623e5a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c80469592134bdf9db0a1ec9232e577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a2cc30a2c447159ba027a0bdbdc050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347ceb56cecd4bf4bd4064819490a10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3437fed2924645ae48d3795ca57fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a96c21f35514fe2a1ecc47e8c51c8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cdf1f3bbf24d349d28fcbb9c89e29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd171e7af8b476298b823f7082c86c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350ef14468b84cf2a560a767e657aaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdb8810e3b34b8d863cfbbbe764600c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ac0c57f42546c88bdf2959afa05374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e057c936e034c649fe93028f33d0b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2132fe162a9d4b46b186539576e286c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4340e555dd674e1dbab9ea43929ba5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully!\n",
      "Flat FAISS index built with 493 vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Load models\n",
    "\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "bert_reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "\n",
    "print(\"Models loaded successfully!\")\n",
    "\n",
    "\n",
    "# Tokenize the documents for BM25\n",
    "tokenized_documents = [doc.split(\" \") for doc in documents]\n",
    "\n",
    "# Initialize BM25\n",
    "bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "# Generate embeddings for FAISS with FlatL2\n",
    "def prepare_flat_faiss_index(documents):\n",
    "    embeddings = np.array([embedding_model.encode(text, convert_to_tensor=False) for text in documents]).astype(\"float32\")\n",
    "    embedding_dim = embeddings.shape[1]\n",
    "\n",
    "    # Create a FlatL2 index\n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # L2 distance\n",
    "    index.add(embeddings)  #\n",
    "    print(f\"Flat FAISS index built with {index.ntotal} vectors.\")\n",
    "    return index, embeddings\n",
    "\n",
    "# Build FAISS FlatL2 index\n",
    "faiss_index, document_embeddings = prepare_flat_faiss_index(documents)\n",
    "\n",
    "# Map for document metadata retrieval\n",
    "document_metadata = {i: {\"Text\": doc} for i, doc in enumerate(documents)}\n",
    "\n",
    "\n",
    "\n",
    "# Hybrid Retrieval\n",
    "def hybrid_retrieval(query, top_k=3):\n",
    "    # Sparse Retrieval with BM25\n",
    "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
    "    top_bm25_indices = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "    sparse_results = [{\"Text\": documents[idx], \"BM25_Score\": bm25_scores[idx]} for idx in top_bm25_indices]\n",
    "\n",
    "    # Dense Retrieval with FAISS\n",
    "    query_embedding = embedding_model.encode(query, convert_to_tensor=False).astype(\"float32\").reshape(1, -1)\n",
    "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
    "    dense_results = [\n",
    "        {\"Text\": document_metadata[idx][\"Text\"], \"FAISS_Distance\": distances[0][i]}\n",
    "        for i, idx in enumerate(indices[0])\n",
    "    ]\n",
    "\n",
    "    # Combine Sparse and Dense Results\n",
    "\n",
    "    seen_texts = set()\n",
    "    combined_results = []\n",
    "    for result in sparse_results + dense_results:\n",
    "        if result[\"Text\"] not in seen_texts:\n",
    "            combined_results.append(result)\n",
    "            seen_texts.add(result[\"Text\"])\n",
    "\n",
    "    # Re-rank results using BERT\n",
    "    rerank_inputs = [(query, result[\"Text\"]) for result in combined_results]\n",
    "    rerank_scores = bert_reranker.predict(rerank_inputs)\n",
    "    for i, result in enumerate(combined_results):\n",
    "        result[\"Rerank_Score\"] = rerank_scores[i]\n",
    "        # Calculate cosine similarity\n",
    "        doc_embedding = embedding_model.encode(result[\"Text\"], convert_to_tensor=False).astype(\"float32\").reshape(1, -1)\n",
    "        result[\"Cosine_Similarity\"] = cosine_similarity(query_embedding, doc_embedding)[0][0]\n",
    "\n",
    "\n",
    "    # Sort by Rerank_Score\n",
    "    final_results = sorted(combined_results, key=lambda x: x[\"Rerank_Score\"], reverse=True)[:top_k]\n",
    "    return final_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-iUcvYvkgTR"
   },
   "source": [
    "## **Using GPT-3.5 as Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66--6CxP7slL"
   },
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMApcicj7M6M",
    "outputId": "b7eec015-af3c-428b-9c20-5344e82fdc11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:··········\n"
     ]
    }
   ],
   "source": [
    "# set up OpenAI\n",
    "import os\n",
    "import openai\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhFDwa4G5Jad"
   },
   "outputs": [],
   "source": [
    "# GPT-3.5 Generator Function\n",
    "def generate_response(input_text, retrieved_context, max_length=100):\n",
    "    #  message for GPT\n",
    "    messages1 = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a professional assistant who provides concise and formal answers.\"},\n",
    "        {\"role\": \"system\", \"content\": f\"Use the following context to answer the question:\\n{retrieved_context}\"},\n",
    "        {\"role\": \"user\", \"content\": input_text}\n",
    "    ]\n",
    "\n",
    "    # OpenAI API call\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages1,\n",
    "        max_tokens=max_length,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Combine retrieved documents into context for the generator\n",
    "def generate_response_with_retrieved_docs(query, retrieved_docs, top_k=3):\n",
    "    retrieved_context = \"\\n\".join([f\"Context: {doc['Text']}\" for doc in retrieved_docs[:top_k]])\n",
    "    input_text = f\"Answer the following query: {query}\"\n",
    "    #print(f\"Input to GPT-3.5 model:\\n{input_text[:750]}...\\n\")  # Print the first 750 characters of the input.\n",
    "    generated_answer = generate_response(input_text, retrieved_context)\n",
    "    return generated_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg5APXu_0GVM",
    "outputId": "d60ac37b-cf70-4a7a-cb13-c237617ba194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Answer:\n",
      " Yes, you need to have a job offer from an employer enrolled and participating in the E-Verify program before applying for STEM OPT.\n"
     ]
    }
   ],
   "source": [
    "# Example: Run the hybrid retrieval and use generator for response\n",
    "query = \"Do I need a job before applying for STEM OPT?\"\n",
    "\n",
    "# Perform hybrid retrieval\n",
    "retrieved_docs = hybrid_retrieval(query, top_k=3)\n",
    "\n",
    "# Generate a detailed answer based on retrieved results\n",
    "generated_answer = generate_response_with_retrieved_docs(query, retrieved_docs, top_k=3)\n",
    "\n",
    "print(\"\\nGenerated Answer:\\n\", generated_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbbXWy2-W__p",
    "outputId": "366bd088-e81f-45f5-a62a-5bc95c77a637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Answer:\n",
      " The Large Language Models course (Course Code: DATA 690) at UMBC is scheduled for next semester. The course is offered in Section 08 on Tuesdays from 7:10 PM to 9:40 PM in Fine Arts 001. The instructor is Donghwa Kim. It is a 3-unit course with 25 total seats, of which 17 are currently available. The instruction mode is hybrid.\n"
     ]
    }
   ],
   "source": [
    "# Example: Run the hybrid retrieval and use generator for response\n",
    "query = \"When is Large Language Models course next semester at UMBC? Give getails about it.\"\n",
    "\n",
    "# Perform hybrid retrieval\n",
    "retrieved_docs = hybrid_retrieval(query, top_k=3)\n",
    "\n",
    "# Generate a detailed answer based on retrieved results\n",
    "generated_answer = generate_response_with_retrieved_docs(query, retrieved_docs, top_k=3)\n",
    "\n",
    "print(\"\\nGenerated Answer:\\n\", generated_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZpM8ohIrO7q"
   },
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zImmsd7AHUfd"
   },
   "outputs": [],
   "source": [
    "def evaluate_all_faqs_with_mean(faqs, top_k=3):\n",
    "    results = []\n",
    "\n",
    "    for idx, faq in enumerate(faqs):  # Iterate over all FAQs\n",
    "        query = faq[\"question\"]\n",
    "        gold_answer = faq[\"answer\"]\n",
    "        print(f\"\\nProcessing FAQ #{idx + 1}\")\n",
    "        print(f\"Query: {query}\")\n",
    "\n",
    "        # Step 1: Retrieve context\n",
    "        retrieved_results = hybrid_retrieval(query, top_k=top_k)\n",
    "\n",
    "        # Extract cosine similarities\n",
    "        cosine_similarities = [result[\"Cosine_Similarity\"] for result in retrieved_results]\n",
    "\n",
    "        # Compute retrieval metric (mean similarity score)\n",
    "        retrieval_score = np.mean(cosine_similarities)\n",
    "        print(f\"Retrieval Metric (Mean Cosine Similarity): {retrieval_score:.4f}\")\n",
    "\n",
    "        # Use the top retrieved context for generation\n",
    "        retrieved_context = \" \".join([result[\"Text\"] for result in retrieved_results])\n",
    "\n",
    "        # Debug: Retrieved results with cosine similarities\n",
    "        print(\"Top Retrieved Results with Cosine Similarities:\")\n",
    "        for i, (text, cos_sim) in enumerate(zip([r[\"Text\"] for r in retrieved_results], cosine_similarities)):\n",
    "            print(f\"Top-{i+1} Text: {text}\\nCosine Similarity: {cos_sim:.4f}\\n\")\n",
    "\n",
    "        # Step 2: Generate response using the retrieved context\n",
    "        generated_response = generate_response(input_text=query, retrieved_context=retrieved_context)\n",
    "\n",
    "        # Debug: Generated response\n",
    "        print(f\"Generated Response:\\n{generated_response}\")\n",
    "\n",
    "        # Step 3: Evaluate the generated response against the gold answer\n",
    "        P, R, F1 = score([generated_response], [gold_answer], lang=\"en\", verbose=False)\n",
    "\n",
    "        # Debug: BERTScore metrics\n",
    "        print(f\"BERTScore - Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1: {F1.mean().item():.4f}\")\n",
    "\n",
    "        # Collect results\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"gold_answer\": gold_answer,\n",
    "            \"retrieved_context\": retrieved_context,\n",
    "            \"generated_response\": generated_response,\n",
    "            \"retrieval_score\": retrieval_score,  # Mean cosine similarity\n",
    "            \"bertscore_precision\": P.mean().item(),\n",
    "            \"bertscore_recall\": R.mean().item(),\n",
    "            \"bertscore_f1\": F1.mean().item(),\n",
    "        })\n",
    "\n",
    "    # Convert results to DataFrame for better visualization\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Compute mean scores for each metric\n",
    "    mean_retrieval_score = results_df[\"retrieval_score\"].mean()\n",
    "    mean_precision = results_df[\"bertscore_precision\"].mean()\n",
    "    mean_recall = results_df[\"bertscore_recall\"].mean()\n",
    "    mean_f1 = results_df[\"bertscore_f1\"].mean()\n",
    "\n",
    "    # Print mean scores\n",
    "    print(\"\\nMean Scores Across All 20 FAQs:\")\n",
    "    print(f\"Mean Retrieval Score (Cosine Similarity): {mean_retrieval_score:.4f}\")\n",
    "    print(f\"Mean BERTScore Precision: {mean_precision:.4f}\")\n",
    "    print(f\"Mean BERTScore Recall: {mean_recall:.4f}\")\n",
    "    print(f\"Mean BERTScore F1: {mean_f1:.4f}\")\n",
    "\n",
    "    return results_df, {\n",
    "        \"mean_retrieval_score\": mean_retrieval_score,\n",
    "        \"mean_precision\": mean_precision,\n",
    "        \"mean_recall\": mean_recall,\n",
    "        \"mean_f1\": mean_f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr29WbHmrO7q"
   },
   "source": [
    "## **Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2df1d1ff8966472aac0548d323b23691",
      "9f692deb9d3f46adb0df3e2cca32c2d7",
      "d386863474e5443ba4a8fb3625473475",
      "e055f2681d9f4bd296c58f89bfbf9d49",
      "3a3c812ebb8f4fa1a3aae9785242abd5",
      "8d6942964a8a49b582acd93c5f39a6ca",
      "b00a3db25e3c413e9fca57f1c658e8c3",
      "b1ecca6db3ba4023af42f36da06e6d0d",
      "f312f5641317401cb2c24a37e35ecb4f",
      "cad97d492f714337910f9f1b781d2e4e",
      "8b2d4c0d2d0346748e4a405077143147",
      "18d76fb273ca450385a632a87facbb26",
      "db58132440e04a21b5f7b5e21db05986",
      "f0f1b12d6797490ebcdebb53cf04d35f",
      "ee8e6dfad8754659b112a51674a0fbcd",
      "3e073877431a45a6abc3b327d26b33fc",
      "de7f39eada2b4f92a2e913da87e9094b",
      "22c3ff670a81410ab7fea6285dcc9dff",
      "c0e44b99d8184f659469e25ea1152e37",
      "d6bca518c05f454bbdef9a8ec0b6080a",
      "4863446551e34aa8a84fc6a73148eb3b",
      "604f68393ab5483d8e8eee6dfc782f67",
      "7a7e390426374a11a9b5ab1f03f701f6",
      "2e0c0e7d2c1a471abea8554718d1c340",
      "1c1f924c0e724b5a9d41d404fcbf743f",
      "9aa84713d599430d828de9b6a0cbf0ae",
      "fe7d1cea821b42b1ba8cedf236ecd872",
      "139aea7969484eb1b1b3c2dca1ecaf3d",
      "91b8c55951e243bea216d1d516e3dc8f",
      "146f2fdc13e940b6a890cad267bdbc77",
      "9ecb712658184e0a913fa888c3d702d9",
      "5425bcbd153645f5927c7bf8dc92319d",
      "52ca94a931c749c8a1f6903a39ab4b19",
      "f73755e0e74c4286b56c354868858e7e",
      "079403a811e941b4a0e72120b9901772",
      "d95fe6df62e742f7b3fc9dc9d21a6438",
      "f4669583662a423a8cbd1ef11a317e30",
      "3e9160695c1643fa97a6125b1f378d5a",
      "342454ae2efd455084ee90eb3196fcb8",
      "2cbb49abcf5542228ae11774ef1e3b56",
      "92bd263a80fd453baae33a7d96968145",
      "1b43e93cc07948ebbfb126ad56e890d0",
      "61aa89671cbd4a83a30cf29e9c6c2870",
      "08689df4a0c74cd68557b055efce2c58",
      "d68f11423351436ab7091f6ebc0f69dd",
      "ac2b32518088421fb0cc8d463cf994ea",
      "3f545ee7c37b425d8aa0aad2d25364e6",
      "5ab3ea4ea4924231ac70051a0e13673e",
      "c0afd9ed7e034b3bb4891b61b67dd8e3",
      "7e2c6d87867a4de295014acc4fe0542f",
      "57d930cb04cd4a7fa918d86c4ee9cd69",
      "e2bfef7e15d94124aae6b131069bd171",
      "c2df69ce80604e4abeb6d8e84278750a",
      "ac2effc2769241848cfc0ae94c7383d9",
      "b2cc8b7df3f44ab488f303f19f36e168",
      "d34bde2951264370a1f2a64297704832",
      "94ebac0d4fa047c4b63d744952270c88",
      "71e5e36f7c8748149fc15bb3005c3263",
      "358d9f16f0c44e04b62efe92e53025fb",
      "b3b5832a51694d92afbbaeb63c68eb63",
      "1061ffbe59164f33b6e7d873dba3f265",
      "99adff84dbfb47fdb14e59e56cf3a677",
      "2504294d409c4f4790c27c14ae0f1acf",
      "fa3683194aac414a8f7b66fbf0104954",
      "84ee101e804c48e68550b7a77e2c4c7c",
      "11736e44e20241f097fb83c7ca36adef"
     ]
    },
    "id": "UOArvV_5JadZ",
    "outputId": "76775643-07f9-4ef5-ce8a-42fca897dd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing FAQ #1\n",
      "Query: What services does the ISSS office provide?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4759\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: the office offers a variety of programming and services to assist students and scholars in pursuit of their academic, personal, and professional goals.\n",
      "Cosine Similarity: 0.4582\n",
      "\n",
      "Top-2 Text: isss office closed on thursday, november 7 if you have a question or concern, please submit a help ticket below and our team will respond as soon as we can. thank you! help ticket the isss office does not respond to emails. instead, we use a help ticket system to send and receive messages.\n",
      "Cosine Similarity: 0.5398\n",
      "\n",
      "Top-3 Text: about oiss umbc office of international students and scholars the office of international students and scholars oiss is dedicated to supporting umbcs international student and scholar community. the office offers a variety of programming and services to assist students and scholars in pursuit of their academic, personal, and professional goals.\n",
      "Cosine Similarity: 0.4296\n",
      "\n",
      "Generated Response:\n",
      "The ISSS office provides a variety of programming and services to support international students and scholars in pursuit of their academic, personal, and professional goals.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df1d1ff8966472aac0548d323b23691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d76fb273ca450385a632a87facbb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a7e390426374a11a9b5ab1f03f701f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73755e0e74c4286b56c354868858e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68f11423351436ab7091f6ebc0f69dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34bde2951264370a1f2a64297704832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.9095, Recall: 0.9127, F1: 0.9111\n",
      "\n",
      "Processing FAQ #2\n",
      "Query: How can I contact the ISSS office?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4730\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: if you have entered the address perfectly and it is not accepted, please contact us on isss website your name, birthday, or other personal details that you can see in the portal are incorrect: please contact us if you notice any errors to information in the portal that you do not have access to.\n",
      "Cosine Similarity: 0.6152\n",
      "\n",
      "Top-2 Text: isss office closed on thursday, november 7 if you have a question or concern, please submit a help ticket below and our team will respond as soon as we can. thank you! help ticket the isss office does not respond to emails. instead, we use a help ticket system to send and receive messages.\n",
      "Cosine Similarity: 0.6122\n",
      "\n",
      "Top-3 Text: if you are in a position to use the cap gap, please contact isss so we can update your I-20 with the cap gap extension to your OPT dates. h-1b portability portability refers to the ability to move your h-1b status from one employer to another.\n",
      "Cosine Similarity: 0.1916\n",
      "\n",
      "Generated Response:\n",
      "You can contact the ISSS office by submitting a help ticket on their website. The office does not respond to emails but uses a help ticket system to send and receive messages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8825, Recall: 0.8866, F1: 0.8846\n",
      "\n",
      "Processing FAQ #3\n",
      "Query: How do I request an I-20?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.6201\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: step 1: request your OPT I-20 students must first request a special OPT I-20 from the isss office. applications submitted to uscis without an OPT I-20 will be denied. students must submit a complete OPT request in the isss portal. first, students choose an OPT start date.\n",
      "Cosine Similarity: 0.6486\n",
      "\n",
      "Top-2 Text: requesting an I-20 in the isss portal once admitted, you will receive an email from our office directing you to complete a new student request application.\n",
      "Cosine Similarity: 0.7354\n",
      "\n",
      "Top-3 Text: students can request another stem OPT I-20 and submit a new i-765 application if there is enough time before the OPT end date. contact isss immediately if your application is denied, and do not resubmit until speaking with an isss advisor. approval the approval notice will list the approved stem OPT start and end dates.\n",
      "Cosine Similarity: 0.4763\n",
      "\n",
      "Generated Response:\n",
      "To request an I-20 for OPT, students must first request a special OPT I-20 from the ISSS office. Applications submitted to USCIS without an OPT I-20 will be denied. Students must submit a complete OPT request in the ISSS portal. First, students choose an OPT start date and then request an I-20 in the ISSS portal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8533, Recall: 0.8749, F1: 0.8640\n",
      "\n",
      "Processing FAQ #4\n",
      "Query: What should I do if my visa expires while in the U.S.?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.5281\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: if your visa is expired and you are outside of the us, you must visit a US embassy to get a new f-1 visa before returning to the us. to renew your visa, you will actually apply for a new one, following the same process as the first time you applied for an f-1 visa.\n",
      "Cosine Similarity: 0.6530\n",
      "\n",
      "Top-2 Text: if you renew your passport, but your visa stamp is in the old passport, you can carry both passports with you until the visa stamp expires and you get a new visa in the new passport.\n",
      "Cosine Similarity: 0.3880\n",
      "\n",
      "Top-3 Text: please remember that you do not need a valid visa to remain the US your visa only allows you to enter the us. while you are here, your I-20 maintains your immigration status, not your visa.\n",
      "Cosine Similarity: 0.5434\n",
      "\n",
      "Generated Response:\n",
      "If your visa expires while you are in the U.S., you do not need to renew it as long as you remain in the country. Your visa only allows you to enter the U.S., and while you are here, your I-20 maintains your immigration status, not your visa. However, if you leave the U.S. and your visa has expired, you will need to visit a U.S. embassy to apply for a new F-1 visa before returning to the U.S.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8817, Recall: 0.8959, F1: 0.8888\n",
      "\n",
      "Processing FAQ #5\n",
      "Query: What is SEVIS, and how do I pay the SEVIS fee?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.5783\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: 2. after you decide which school you will attend and have an I-20 from that school, you will need to pay the i-901 sevis fee for that sevis id found a the top right of the i-20. this is a one-time fee, which is used to maintain the immigration database that manages international student and scholar information.\n",
      "Cosine Similarity: 0.6069\n",
      "\n",
      "Top-2 Text: please note you will need to take your sevis fee receipt to your visa appointment. 3. next, complete a ds-160 visa application form, the ds-160 has a US $185 application fee, which you often cannot pay until you actually schedule your visa appointment. each embassy handles this a bit differently.\n",
      "Cosine Similarity: 0.5955\n",
      "\n",
      "Top-3 Text: sevp portal help the sevp portal is a tool students use to report their employer information and maintain f-1 status while on opt. sevp is the student and exchange visitor program, a US government specialized immigration organization. sevis is the student and exchange visitor information system, where the immigration records of students are maintained.\n",
      "Cosine Similarity: 0.5325\n",
      "\n",
      "Generated Response:\n",
      "SEVIS stands for Student and Exchange Visitor Information System. It is a system used to maintain the immigration records of international students in the United States. To pay the SEVIS fee, you will need to have an I-20 from the school you plan to attend, locate the SEVIS ID on the top right of the I-20, and then pay the one-time SEVIS fee using the SEVIS fee payment portal. You will need to bring the SEVIS fee receipt to your visa appointment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8817, Recall: 0.9386, F1: 0.9092\n",
      "\n",
      "Processing FAQ #6\n",
      "Query: What are the full-time enrollment requirements?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.5978\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: enrollment requirements: must enroll in half of full-time enrollment at least 5 credits for graduate students, at least 6 credits for undergraduate students requirements to be approved: email or letter from course instructor or academic advisor, recommending that the student be allowed to drop the class for one of the following reasons: improper course placement this option is appropriate for students who were advised inappropriately and have taken classes out of sequence, or who were inappropriately allowed to take a course for which they did not have the prerequisite knowledge to be successful.\n",
      "Cosine Similarity: 0.6302\n",
      "\n",
      "Top-2 Text: summer and winter session enrollment is optional it is not required unless you plan to complete your academic program during a summer term, in which case you must follow all full-time enrollment rules. definition of full-time enrollment graduate students- graduate students are required to enroll in a minimum of 9 credits per semester.\n",
      "Cosine Similarity: 0.6076\n",
      "\n",
      "Top-3 Text: f-1 enrollment requirements and exceptions enrollment requirements international students in f-1 immigration status are required by immigration law to be enrolled full-time during the regular semesters fall and spring.\n",
      "Cosine Similarity: 0.5557\n",
      "\n",
      "Generated Response:\n",
      "For graduate students, the full-time enrollment requirement is a minimum of 9 credits per semester. International students in F-1 immigration status must be enrolled full-time during the regular semesters of fall and spring.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8624, Recall: 0.9180, F1: 0.8893\n",
      "\n",
      "Processing FAQ #7\n",
      "Query: Can I take a Reduced Course Load (RCL)?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.6860\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: possible exceptions to full-time enrollment requirements the immigration language for receiving permission to enroll less than full-time is a reduced course load rcl. any rcl must be approved in advance with isss, before the semester begins in which you plan to be enrolled part-time.\n",
      "Cosine Similarity: 0.6431\n",
      "\n",
      "Top-2 Text: 2. medical reduced course load rcl duration: approved one semester at a time, can be granted until the deadline to drop classes during a semester limitations: up to 12 months cumulative during one degree program enrollment requirements: enrollment can be part-time or not at all requirements to be approved: you must provide a note from your doctor indicating their recommendation that you do not study full-time this semester based on a medical situation.\n",
      "Cosine Similarity: 0.7516\n",
      "\n",
      "Top-3 Text: in some cases, an rcl can be approved during the semester if you need to drop the class. please note these rules are very strict and the exceptions are not very accommodating please plan appropriately!\n",
      "Cosine Similarity: 0.6634\n",
      "\n",
      "Generated Response:\n",
      "To take a Reduced Course Load (RCL), you must meet specific criteria outlined by the immigration regulations. One possible exception is for medical reasons, where you would need to provide a note from your doctor recommending that you do not study full-time due to a medical situation. The RCL must be approved in advance by the International Student and Scholar Services (ISSS) before the semester begins. It is important to note that RCL approvals are limited and must be requested and granted within the specified guidelines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8412, Recall: 0.8768, F1: 0.8587\n",
      "\n",
      "Processing FAQ #8\n",
      "Query: Can I take online classes?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4916\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: online courses can be taken as much as you like in summer or winter sessions, when enrollment is not required, unless you plan to complete your academic program during a summer term, in which case you must follow all full-time enrollment rules and are only permitted to take at most one fully-online course.\n",
      "Cosine Similarity: 0.6302\n",
      "\n",
      "Top-2 Text: for example, an undergraduate could take one online course for 3 credits, 3 regular courses for 9 credits, and thats the required 12. beyond the required 12, an additional online course could be taken.\n",
      "Cosine Similarity: 0.4989\n",
      "\n",
      "Top-3 Text: undergraduate students- undergrads are required to enroll in a minimum of 12 credits per semester. one class is typically 3 or 4 credits. online coursework immigration regulations allow for one online class per semester towards your minimum requirement. you could take additional online courses beyond your minimum enrollment as well, if you like.\n",
      "Cosine Similarity: 0.3457\n",
      "\n",
      "Generated Response:\n",
      "Yes, you can take online classes. Online courses can be taken during summer or winter sessions without enrollment requirements. However, if you plan to complete your academic program during a summer term, you must follow full-time enrollment rules and are only allowed to take at most one fully-online course.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8853, Recall: 0.8791, F1: 0.8822\n",
      "\n",
      "Processing FAQ #9\n",
      "Query: What is CPT, and how do I apply?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.6173\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: cpt: off-campus work authorization curricular practical training cpt allows f-1 international students to work off-campus in paid positions within the us. cpt requires an application completed by the student, which can be submitted via the isss portal. once approved, isss will add cpt work authorization to the students immigration record, and issue a new form I-20 noting the work authorization.\n",
      "Cosine Similarity: 0.6694\n",
      "\n",
      "Top-2 Text: cpt approval is granted per semester if a position continues to the next semester, students will need to request cpt again for the next term. students are eligible to start working from the date they are approved by isss. isss cannot approve cpt for dates that have passed. please plan ahead and apply early!\n",
      "Cosine Similarity: 0.6013\n",
      "\n",
      "Top-3 Text: before you start: cpt checklist required materials: upload a copy of your job offer letter request recommendations from your academic advisors undergraduate students only need a recommendation from their academic advisor. graduate students need a recommendation from both their academic advisor and graduate program director.\n",
      "Cosine Similarity: 0.5812\n",
      "\n",
      "Generated Response:\n",
      "CPT stands for Curricular Practical Training, which allows F-1 international students to work off-campus in paid positions within the US. To apply for CPT, you need to complete an application through the ISSS portal. Required materials include a copy of your job offer letter and recommendations from your academic advisors. Undergraduate students need a recommendation from their academic advisor, while graduate students need recommendations from both their academic advisor and graduate program director. Once approved, ISSS will add CPT work authorization to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8682, Recall: 0.9181, F1: 0.8924\n",
      "\n",
      "Processing FAQ #10\n",
      "Query: What is OPT, and when can I apply?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.6523\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: opt: post-graduation work authorization students who plan on working in a paid position after completing their program must receive work authorization. OPT optional practical training is a type of work permission available for f-1 international students who finish their program requirements. OPT is approved by u.s. citizen and immigration services uscis, with support from the university isss office.\n",
      "Cosine Similarity: 0.6594\n",
      "\n",
      "Top-2 Text: eligibility to be eligible for opt, students must meet following criteria: currently enrolled at umbc full time with active f-1 status completed two consecutive academic semesters fall and spring in the US completed all program requirements for degree exceptions for graduate students who only have a thesisdissertation remaining have not been previously granted OPT at the current level of study have not been approved for 12 months or more of full time curricular practical training cpt application process students must first receive a special OPT I-20 from the isss office before submitting their OPT application to uscis.\n",
      "Cosine Similarity: 0.6655\n",
      "\n",
      "Top-3 Text: OPT is granted only once per education level. once approved by uscis: students are approved for 1 year of work authorization. students cannot begin working before the start date on their employment authorization document ead card. students must work a combined total of at least 20 hoursweek. positions can be unpaidpaid and with multiple employers.\n",
      "Cosine Similarity: 0.6320\n",
      "\n",
      "Generated Response:\n",
      "OPT stands for Optional Practical Training, which is a type of work permission available for F-1 international students who have completed their program requirements. To be eligible for OPT, you must be currently enrolled full-time with active F-1 status, have completed two consecutive academic semesters in the US, and have completed all program requirements for your degree. You can apply for OPT after meeting these criteria and receiving a special OPT I-20 from the ISSS office.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8472, Recall: 0.8837, F1: 0.8651\n",
      "\n",
      "Processing FAQ #11\n",
      "Query: What is STEM OPT, and how is it different?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.6398\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: stem OPT follows federal and school regulations: all work done pursuant to stem OPT must be directly related to the students major program of study. students must first request and receive a special stem OPT I-20 from the isss office before submitting their application to uscis. stem OPT is granted only once per degree level.\n",
      "Cosine Similarity: 0.6765\n",
      "\n",
      "Top-2 Text: eligibility to be eligible for stem opt, students must meet following criteria: currently in active f-1 status currently participating in one year of regular OPT completed all program requirements for a stem-eligible degree pursuing work with an employer enrolled and participating in the e-verify program have not been previously granted optstem OPT at the current level of study application process the application process for stem OPT is very similar to applying for regular opt.\n",
      "Cosine Similarity: 0.6290\n",
      "\n",
      "Top-3 Text: stem OPT extension students who have graduated from umbc with a dhs-designated stem degree can extend their initial year of OPT optional practical training via the stem OPT extension. this type of work authorization is available to f-1 international students who have completed their program requirements and have already been approved for an initial period of regular opt.\n",
      "Cosine Similarity: 0.6140\n",
      "\n",
      "Generated Response:\n",
      "STEM OPT stands for Science, Technology, Engineering, and Mathematics Optional Practical Training. It is an extension of the regular Optional Practical Training (OPT) program available to F-1 international students who have completed a degree in a STEM field. The main difference between STEM OPT and regular OPT is that STEM OPT allows for an additional 24 months of work authorization, totaling up to 36 months of practical training in the United States.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8342, Recall: 0.8750, F1: 0.8541\n",
      "\n",
      "Processing FAQ #12\n",
      "Query: What documents do I need to travel internationally?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.2097\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: travel abroad and visa renewal during OPT travelling abroad during OPT or stem OPT you can absolutely travel abroad during opt, but the there are a few additional pieces to prepare than the typical documents required for current students.\n",
      "Cosine Similarity: 0.0867\n",
      "\n",
      "Top-2 Text: request a travel signature: please submit an I-20 reprint request via the isss portal please see our website specific to travel and visa renewal during i-515 temporary entry if you are missing documents when you try to enter the us, the cbp officer can choose to refuse you entry to the us, or give you an i-515 document allowing you a temporary stay in the us, during which time you will need to provide the missing documents.\n",
      "Cosine Similarity: 0.2453\n",
      "\n",
      "Top-3 Text: if flying, do not pack your immigration documents in your checked luggage make sure to carry them in your carry-on luggage. plan your flights appropriately if you will need a connecting flight after you first land in the us, remember that you will need to go through customs first, which can often take 1-2 hours if the process is smooth.\n",
      "Cosine Similarity: 0.2969\n",
      "\n",
      "Generated Response:\n",
      "To travel internationally during OPT or STEM OPT, you will need your valid passport, F-1 visa, I-20 with a recent travel signature, EAD card, and any other relevant documents specific to your travel destination. Make sure to carry these documents in your carry-on luggage and not in your checked luggage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8468, Recall: 0.9133, F1: 0.8788\n",
      "\n",
      "Processing FAQ #13\n",
      "Query: Can I travel with an expired visa?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4275\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: short trips to canada, mexico or some caribbean islands with an expired f-1 visa automatic visa revalidation students who have a valid I-20 and are in good f-1 status, but whose visa has expired, are able to take short trips less than 30 days to countries neighboring the US to canada, mexico and some caribbean islands.\n",
      "Cosine Similarity: 0.4090\n",
      "\n",
      "Top-2 Text: travel abroad and visa renewal your f-1 immigration status makes it easy for you to take vacations and short trips abroad, outside of the us! make sure to plan ahead for smooth travels. dont forget your I-20 travel signature! travel checklist passport check your passport to make sure it is valid. you cant travel at all without a valid passport!\n",
      "Cosine Similarity: 0.3951\n",
      "\n",
      "Top-3 Text: if you renew your passport, but your visa stamp is in the old passport, you can carry both passports with you until the visa stamp expires and you get a new visa in the new passport.\n",
      "Cosine Similarity: 0.4785\n",
      "\n",
      "Generated Response:\n",
      "If you have an expired F-1 visa but a valid I-20 and are in good F-1 status, you may be able to take short trips to certain countries neighboring the US, such as Canada, Mexico, and some Caribbean islands, under the Automatic Visa Revalidation program. It is important to review the specific requirements and restrictions before traveling with an expired visa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8429, Recall: 0.9109, F1: 0.8756\n",
      "\n",
      "Processing FAQ #14\n",
      "Query: What is Automatic Visa Revalidation?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4995\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: please read more about automatic visa revalidation, and see the list of eligible destinations please also note this rule is only for re-entry to the us, and does not play a role in allowing you to enter the country you plan to visit.\n",
      "Cosine Similarity: 0.5777\n",
      "\n",
      "Top-2 Text: f-1 visa process a visa is a document that allows you to enter the US in a certain kind of status, and determines the restrictions and opportunities you have in the US based on the visa category you enter in, as well as how long you can stay in the us.\n",
      "Cosine Similarity: 0.4691\n",
      "\n",
      "Top-3 Text: administrative processing simply means that the consular officer feels they need more information to make a decision on your visa application. administrative processing is more common for academic programs considered to be sensitive to US national security, such as biotechnology or certain kinds of engineering.\n",
      "Cosine Similarity: 0.4516\n",
      "\n",
      "Generated Response:\n",
      "Automatic Visa Revalidation is a process that allows certain nonimmigrant visa holders to re-enter the United States from a brief trip to Canada, Mexico, or adjacent islands without having to obtain a new visa stamp, as long as certain conditions are met. It is important to note that this rule only applies to re-entry to the US and does not affect entry into the country being visited.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8775, Recall: 0.9026, F1: 0.8899\n",
      "\n",
      "Processing FAQ #15\n",
      "Query: What are my options after graduation?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.3037\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: to this extent, students that have completed their required coursework but have not defended their thesis and graduated can choose to end their I-20 and apply for opt.\n",
      "Cosine Similarity: 0.3765\n",
      "\n",
      "Top-2 Text: stem OPT extension students who have graduated from umbc with a dhs-designated stem degree can extend their initial year of OPT optional practical training via the stem OPT extension. this type of work authorization is available to f-1 international students who have completed their program requirements and have already been approved for an initial period of regular opt.\n",
      "Cosine Similarity: 0.3580\n",
      "\n",
      "Top-3 Text: f-1 immigration rules work options for f-1 students billing and health insurance about US and umbc culture programs and services available on campus spring 2025 orientation international student orientation takes part in 2 sessions, both are mandatory!\n",
      "Cosine Similarity: 0.1766\n",
      "\n",
      "Generated Response:\n",
      "After graduation, you can choose to apply for Optional Practical Training (OPT) to gain work experience in your field of study. If you have completed a DHS-designated STEM degree from UMBC, you may be eligible to extend your initial OPT period through the STEM OPT extension. Additionally, you can participate in programs and services available on campus and attend mandatory international student orientation sessions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8414, Recall: 0.8670, F1: 0.8540\n",
      "\n",
      "Processing FAQ #16\n",
      "Query: What is the grace period after completing my program?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4383\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: students can request another OPT I-20 and submit a new i-765 application if their 60 day grace period has not ended. contact the isss office about any questions or concerns. approval the approval notice will list the approved OPT start and end dates. however, students cannot begin working until their physical ead card arrives in the mail.\n",
      "Cosine Similarity: 0.4789\n",
      "\n",
      "Top-2 Text: please note, you must work with us to get your new I-20 before your current I-20 end date, plus the 60 day grace period.\n",
      "Cosine Similarity: 0.3398\n",
      "\n",
      "Top-3 Text: I-20 program extension the program dates specified in the program of study section of your form I-20 reflect the typical duration for completing your degree program. however, certain circumstances may require additional time for students to complete their studies and graduate. if you require more time, you must apply for an extension of your I-20 program to ensure its validity.\n",
      "Cosine Similarity: 0.4962\n",
      "\n",
      "Generated Response:\n",
      "The grace period after completing your program is typically 60 days.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.9062, Recall: 0.8633, F1: 0.8842\n",
      "\n",
      "Processing FAQ #17\n",
      "Query: How do I access the ISSS Portal?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4388\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: when a student receives an OPT recommendation from our office, we send out an email with instructions on how to set up an isss portal account using a personal email address. students on OPT will need to login using their personal email address to access the isss portal.\n",
      "Cosine Similarity: 0.5286\n",
      "\n",
      "Top-2 Text: how to access your I-20 how to access your signed electronic umbc form i-20: request your I-20 in the isss portal the umbcs isss team will contact you via email when your I-20 is ready. it will be attached to your original request under the documents tab.\n",
      "Cosine Similarity: 0.3747\n",
      "\n",
      "Top-3 Text: if you have entered the address perfectly and it is not accepted, please contact us on isss website your name, birthday, or other personal details that you can see in the portal are incorrect: please contact us if you notice any errors to information in the portal that you do not have access to.\n",
      "Cosine Similarity: 0.4131\n",
      "\n",
      "Generated Response:\n",
      "To access the ISSS Portal, you need to set up an account using your personal email address. Once your account is created, you can log in using your personal email address to access the ISSS Portal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8437, Recall: 0.8522, F1: 0.8479\n",
      "\n",
      "Processing FAQ #18\n",
      "Query: What should I do if I lose my passport or I-20?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.4879\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: request a travel signature: please submit an I-20 reprint request via the isss portal please see our website specific to travel and visa renewal during i-515 temporary entry if you are missing documents when you try to enter the us, the cbp officer can choose to refuse you entry to the us, or give you an i-515 document allowing you a temporary stay in the us, during which time you will need to provide the missing documents.\n",
      "Cosine Similarity: 0.5139\n",
      "\n",
      "Top-2 Text: copy of new I-20 issued by international advisor recommending economic hardship. checkmoney order for $410 only made out to the department of homeland security. do not abbreviate 2 passport size photographs. copy of your I-94 front and back of card, or printed record from cbp website. copy of your passport biography page include pages of passport extensions showing passport validity.\n",
      "Cosine Similarity: 0.4594\n",
      "\n",
      "Top-3 Text: passport your passport allows you to travel outside of your country, as well as return home again. please keep your passport in a safe place, and do not carry your passport with you in the us. ies recommends carrying a photocopy of your passport with you. your passport should never be allowed to expire.\n",
      "Cosine Similarity: 0.4905\n",
      "\n",
      "Generated Response:\n",
      "If you lose your passport, you should report it to the nearest embassy or consulate of your country. To replace your I-20, you should contact your international advisor at your educational institution to request a reprint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.9008, Recall: 0.8991, F1: 0.8999\n",
      "\n",
      "Processing FAQ #19\n",
      "Query: How do I get a Social Security Number (SSN)?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.6128\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: ssn are issued by the united states social security administration ssa. to start the process, students should submit a ssn letter request in the isss portal. after a student has an I-20 with cpt approval and a receipt from the ssa, they present these documents to their employers human resources department.\n",
      "Cosine Similarity: 0.6255\n",
      "\n",
      "Top-2 Text: applying for a social security number ssn an ssn is required of any individual in order to get paid in the us.\n",
      "Cosine Similarity: 0.6088\n",
      "\n",
      "Top-3 Text: when you receive your first job offer, you will need to apply for a social security number ssn if you dont already have one. an ssn is required to be paid in the us. to learn more about what an ssn is and how to apply, please review the information in this website .\n",
      "Cosine Similarity: 0.6042\n",
      "\n",
      "Generated Response:\n",
      "To obtain a Social Security Number (SSN) in the United States, you need to follow these steps:\n",
      "1. Submit a SSN letter request in the ISSS portal.\n",
      "2. Obtain an I-20 with CPT approval.\n",
      "3. Receive a receipt from the Social Security Administration (SSA).\n",
      "4. Present the I-20 with CPT approval and the SSA receipt to your employer's human resources department.\n",
      "5. Apply for a SSN with the required documents.\n",
      "6. An\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8383, Recall: 0.8806, F1: 0.8589\n",
      "\n",
      "Processing FAQ #20\n",
      "Query: What should I do if my I-20 is about to expire?\n",
      "Retrieval Metric (Mean Cosine Similarity): 0.6087\n",
      "Top Retrieved Results with Cosine Similarities:\n",
      "Top-1 Text: deadline please note that your form I-20 can only be extended up until the current end date. after your current I-20 end date passes, we can no longer extend the date into the future. it is important to plan ahead for this deadline.\n",
      "Cosine Similarity: 0.5679\n",
      "\n",
      "Top-2 Text: please note, you must work with us to get your new I-20 before your current I-20 end date, plus the 60 day grace period.\n",
      "Cosine Similarity: 0.6465\n",
      "\n",
      "Top-3 Text: step 3: request an I-20 reprint if needed you will need an updated I-20 if: your employer requests it from you you need to renew your drivers license you plan on travelling abroad in the next 6 months note: students on OPT will not be able to access the isss portal using their myumbc credentials.\n",
      "Cosine Similarity: 0.6116\n",
      "\n",
      "Generated Response:\n",
      "If your I-20 is about to expire, you should work with the appropriate office to request an extension before the current end date. It is important to plan ahead and ensure that you have the updated I-20 before your current I-20 end date, plus the 60-day grace period. If needed, you can request an I-20 reprint for reasons such as employer requests, driver's license renewal, or upcoming international travel within the next 6 months.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore - Precision: 0.8523, Recall: 0.8815, F1: 0.8666\n",
      "\n",
      "Mean Scores Across All 20 FAQs:\n",
      "Mean Retrieval Score (Cosine Similarity): 0.5194\n",
      "Mean BERTScore Precision: 0.8649\n",
      "Mean BERTScore Recall: 0.8915\n",
      "Mean BERTScore F1: 0.8778\n",
      "\n",
      "Mean Scores:\n",
      "{'mean_retrieval_score': 0.51935446, 'mean_precision': 0.8648564994335175, 'mean_recall': 0.891491037607193, 'mean_f1': 0.8777661472558975}\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation and get results\n",
    "faq_results, mean_scores = evaluate_all_faqs_with_mean(faqs, top_k=3)\n",
    "\n",
    "\n",
    "# Display mean scores\n",
    "print(\"\\nMean Scores:\")\n",
    "print(mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k2eVQYRnJdTl",
    "outputId": "297c2523-9be2-4b6f-c31f-bef465a06c37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Scores:\n",
      "{'mean_retrieval_score': 0.51935446, 'mean_precision': 0.8648564994335175, 'mean_recall': 0.891491037607193, 'mean_f1': 0.8777661472558975}\n"
     ]
    }
   ],
   "source": [
    "# Display mean scores\n",
    "print(\"\\nMean Scores:\")\n",
    "print(mean_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Ot-NZ4SXm2"
   },
   "source": [
    "#**Building a Retrieval-Augmented Generation (RAG) System Using UMBC ISSS Data**\n",
    "\n",
    "###**Introduction**\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a cutting-edge approach in natural language processing (NLP). It combines the power of retrieval systems with generative models, enabling precise and contextually aware responses to user queries. In this project, we built a RAG system leveraging UMBC ISSS (International Student & Scholar Services) data to provide meaningful responses by utilizing a retrieval pipeline backed by FAISS and BM25 and a generator powered by GPT-3.5.\n",
    "\n",
    "###**Objective**\n",
    "\n",
    "The goal of this project was to create an efficient RAG system that:\n",
    "\n",
    "1. Processes and breaks down large, unstructured text data (sourced from Word documents).\n",
    "\n",
    "2. Preprocesses and embeds the text data for effective retrieval.\n",
    "\n",
    "3. Ranks and retrieves the most relevant chunks using cross-encoders.\n",
    "\n",
    "4. Generates accurate and user-friendly responses tailored to a given query.\n",
    "\n",
    "###**System Workflow**\n",
    "\n",
    "####**1. Data Source and Preprocessing**\n",
    "\n",
    "The input for our system was a collection of Word documents containing UMBC ISSS data. To make this information machine-readable and queryable, the preprocessing involved:\n",
    "\n",
    "* Extracting text from Word documents using libraries like python-docx.\n",
    "\n",
    "* Cleaning the extracted text to remove noise, such as special characters and URLs.\n",
    "\n",
    "* Breaking down the cleaned text into semantically meaningful chunks using sentence tokenization and token size limits.\n",
    "\n",
    "* Adding contextual metadata to each chunk, including DocumentID, ChunkID, and Text, and saving them as JSON files.\n",
    "\n",
    "\n",
    "\n",
    "####**2. Embedding the Data**\n",
    "\n",
    "Once the data was preprocessed, we utilized Sentence Transformers to embed the text into high-dimensional vector representations. This embedding phase was crucial for enabling similarity-based retrieval.\n",
    "\n",
    "**Key Steps:**\n",
    "\n",
    "* Used pre-trained models from the Sentence Transformers library (e.g., all-mpnet-base-v2).\n",
    "\n",
    "* Converted each JSON chunk’s text field into an embedding vector.\n",
    "\n",
    "* Stored the embeddings in a FAISS index for efficient similarity searches.\n",
    "\n",
    "####**3. Retrieval Pipeline**\n",
    "\n",
    "Retrieval was implemented using a hybrid approach:\n",
    "\n",
    "1. **BM25:** A traditional sparse vector retrieval method that quickly identifies potentially relevant chunks based on keyword matching.\n",
    "\n",
    "2. **FAISS:** A dense vector retrieval method used for precise similarity scoring based on embeddings.\n",
    "\n",
    "3. **Cross-Encoders:** Leveraging models like BERT for re-ranking the retrieved documents, ensuring the highest relevance for user queries.\n",
    "\n",
    "This combination ensured both speed and accuracy in identifying the top-ranked documents for any given query.\n",
    "\n",
    "####**4. Generative Response**\n",
    "\n",
    "To craft meaningful and query-specific responses:\n",
    "\n",
    "* Generator Model: GPT-3.5 was used to generate natural language responses.\n",
    "\n",
    "* Optimization: The generator took the query along with the top-ranked retrieved chunks as context, ensuring the response was both accurate and comprehensive.\n",
    "\n",
    "\n",
    "###**Implementation Details**\n",
    "\n",
    "####**Preprocessing Notebook**\n",
    "\n",
    "The preprocessing pipeline was implemented in Python using Jupyter Notebook. Key components included:\n",
    "\n",
    "* **Text Extraction:** Extracted text from Word documents and other supported file formats.\n",
    "\n",
    "* **JSON Chunking:** Divided the text into smaller JSON chunks based on semantic and token size constraints.\n",
    "\n",
    "**Contextual Metadata:** Added context to each chunk to improve retrieval performance.\n",
    "\n",
    "####**RAG Pipeline Notebook**\n",
    "\n",
    "The main RAG pipeline combined the retrieval and generation processes:\n",
    "\n",
    "**Embedding Phase:**\n",
    "\n",
    "* Imported pre-trained models from Sentence Transformers.\n",
    "\n",
    "* Indexed embeddings using FAISS for dense similarity searches.\n",
    "\n",
    "**Retrieval Phase:**\n",
    "\n",
    "* Initial document filtering using BM25.\n",
    "\n",
    "* Dense retrieval via FAISS.\n",
    "\n",
    "* Re-ranking the results using BERT-based cross-encoders for enhanced relevance.\n",
    "\n",
    "**Response Generation:**\n",
    "\n",
    "* Integrated GPT-3.5 for generating human-like responses.\n",
    "\n",
    "* Provided the query and top-ranked chunks as input context to the generator.\n",
    "\n",
    "###**Challenges and Solutions**\n",
    "\n",
    "**Challenge:** Processing large Word documents efficiently.\n",
    "\n",
    "* **Solution:** Implemented robust preprocessing scripts to automate text extraction and segmentation.\n",
    "\n",
    "**Challenge:** Balancing retrieval speed and accuracy.\n",
    "\n",
    "* **Solution:** Hybrid retrieval with BM25 for speed and FAISS + cross-encoders for precision.\n",
    "\n",
    "**Challenge:** Ensuring coherent and context-aware responses.\n",
    "\n",
    "* **Solution:** GPT-3.5 was optimized to generate responses tailored to the retrieved content.\n",
    "\n",
    "\n",
    "###**Results and Applications**\n",
    "\n",
    "The RAG system successfully demonstrated:\n",
    "\n",
    "**Efficient Retrieval:** Rapid identification of relevant text chunks.\n",
    "\n",
    "* **Accurate Generation:** Context-aware responses that addressed user queries comprehensively.\n",
    "\n",
    "* **Scalability:** A modular architecture that can handle additional datasets or integrate with other domains seamlessly.\n",
    "\n",
    "Potential applications include:\n",
    "\n",
    "* Assisting international students with quick answers to frequently asked questions.\n",
    "\n",
    "* Supporting administrative tasks by summarizing or reformatting ISSS information.\n",
    "\n",
    "* Enhancing user experience through personalized query handling.\n",
    "\n",
    "\n",
    "###**Conclusion**\n",
    "\n",
    "This project showcased the potential of RAG systems in making large-scale unstructured data actionable and user-friendly. By combining advanced retrieval mechanisms with state-of-the-art generative models, we bridged the gap between static document repositories and dynamic, query-driven information access.\n",
    "\n",
    "Stay tuned for a step-by-step guide on replicating this pipeline for your own data sources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQ-6pnpNtFGN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
